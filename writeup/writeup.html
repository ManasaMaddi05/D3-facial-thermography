<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Dashboard Write‑Up</title>
  <link rel="stylesheet" href="../style.css" />
</head>
<body>
  <nav class="navbar">
    <a href="../index.html">Home</a>
    <a href="writeup.html">Write‑Up</a>
  </nav>

  <div class="container">
    <h1>Final Write‑Up</h1>

    <!-- 1. Motivation -->
    <section>
      <h2>1. Motivation & Compelling Question</h2>
      <p>
        Our dashboard answers the question:  
        <em>“How well do different facial regions (forehead, inner canthi, mouth) track true oral temperature under various ambient conditions and demographics?”</em>
      </p>
    </section>
    <section>
      <h2>2. Data Source & Subsetting</h2>
      <ul>
        <li>We utilized a database titled “Facial and oral temperature data from a large set of human subject volunteers” from PhysioNet for our data visualization.</li>
        <li>The researchers utilized infrared thermography (IRT) to measure different facial and oral temperatures of 1,020 individuals on 
          IRT-1 and 1,009 individuals on IRT-2. The dataset includes information on temperatures in the forehead, mouth, eye, and internal 
          oral regions, demographic data like gender, age, and ethnicity, and situational factors like cosmetic usage (y/n) and relative humidity. 
          All personal identification information (PII) had been removed. The data was divided across six CSV files, and we wrangled and combined the 
          data for each sensor type to two datasets–one for Group 1 (ambient temperature 20-24 degrees Celsius) and Group 2 (ambient temperature 24-28 degrees Celsius).</li>
      </ul>
    </section>

    <section>
      <h2> 3. Visual Encoding & Interaction Rationale</h2>
      <h3>Encodings</h3>
      <ul>
        <li>Red glow: This was used when “Show Medical Alerts” was turned on and a high fever was predicted. Its purpose was to highlight the urgency of the prediction</li>
        <li>Red color: This color was chosen because it represents a high predicted temperature and this choice was made as we typically associate red with being a hot color.</li>
        <li>Blue color: This was used for colder internal temperatures and this choice was made as our brains associated blue with being a cooler color.</li>
      </ul>

      <h3>Interaction Techniques</h3>
      <ul>
        <li>Slider for temperature: Allows users to see the correlation between one facial area and other facial areas through color similarity.
        </li>
        <li>Dropdown Filters: Allows users to filter “Age Range” and “Gender” to show a more specific facial temperature in real-time. </li>
        <li>Checkbox for medical alerts: Emphasizes the facial dots that are past a threshold–indicating a fever or medical attention.</li>
        <li>Tooltips on Facial Dots: Allows users to see the specific temperature of each facial area.</li>
        <li>Auto Diagnostic: If certain areas are above a set threshold, the “Auto-Diagnostic” box will state reasons and prescribe courses of action.</li>
      </ul>

      <h3>Alternatives Considered</h3>
      <ul>
        <li>We initially considered creating a heatmap grid with all the different areas measured by the research study, including internal oral temperature, 
          to better show the correlation of predicting internal temperature. However, for this project, we wanted to integrate an actual face and simply visualize
           how temperatures change across the face as opposed to internal temperature prediction. Thus, we went with our current face visualization idea.
        </li>
      </ul>
    </section>

    <section>
      <h2>4. Team & Development Process</h2>
      
      <ul>
        <li>
          Our team worked closely together during the development process. After spending some time brainstorming and discussing the outline of the final 
          visualization and the features it would have, we agreed on a structure and how to split the tasks
          </li>

        <li>Manasa: Initial Website design on homepage and added the diagnostics</li>
        <li>Rakshan: Connecting the data to D3 and calculating the offers</li>
        <li>Andrew: Improved website layout and added writeup</li>
        <li>Despite split responsibilities, our team continually maintained consistent communication and meetings to discuss progress, ask questions, 
          and suggest features that we could add. This allowed our team to follow our timeline in an efficient and creative manner.
        </li>
      </ul>

      <h3>Workflow & Time</h3>
      <ul>
        <li><strong>Total effort:</strong> ~30 people‑hours</li>
        <li>To work on the project, we had in person and online meetings while having a group
           chat on the side to post questions and updates.</li>
        <li>The aspects that took the most time was pulling/wrangling the data before calculating the temperature offsets in D3.
        </li>
      </ul>
    </section>
  </div>
</body>
</html>
